{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd44a24-c786-4d02-8df9-f2f06e1c8a87",
   "metadata": {},
   "source": [
    "Testing to see if I can utilize the GPUs on my MacBook M1 Max.\n",
    "\n",
    "Main test from here: https://github.com/mrdbourke/mac-ml-speed-test,\n",
    "modified to run with the versions of the software I could install in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5cfe85ff-060d-4e0e-8dd6-fba5e21f408a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device = mps_device)\n",
    "    print(x)\n",
    "else:\n",
    "    print(\"MPS device not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ca5a4c49-367d-4b1c-8643-7d4254265d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003037499263882637"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "import random\n",
    "\n",
    "x = torch.ones(500000000, device='mps')\n",
    "timeit.timeit(lambda:x * random.randint(0, 100), number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84edd018-7ed8-4df5-859b-25f56f63b300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012535833055153489"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(50000000, device=\"cpu\")\n",
    "timeit.timeit(lambda:x * random.randint(0,100), number = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7bd44a-a08c-4817-aa36-3775bde92c82",
   "metadata": {},
   "source": [
    "There definitely is a time difference, but the source I am comparing this to had 0.0003982 and 0.0112392, so overall the numbers I am seeing are off by a bit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a281d26a-1514-4547-b1a6-7d653434e58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time with cpu (10000): 0.0004969999999957508\n",
      "Total time with cpu (100000000): 0.44410700000025827\n",
      "Total time with cpu (10000): 9.700000009615906e-05\n",
      "Total time with cpu (100000000): 0.43829399999958696\n",
      "Total time with cpu (10000): 0.0001229999998031417\n",
      "Total time with cpu (100000000): 0.44238900000073045\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4459919999999329\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.4349770000007993\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.43922099999963393\n",
      "Total time with cpu (10000): 8.000000070751412e-05\n",
      "Total time with cpu (100000000): 0.44181899999966845\n",
      "Total time with cpu (10000): 9.799999952520011e-05\n",
      "Total time with cpu (100000000): 0.43906199999946693\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.44361599999956525\n",
      "Total time with cpu (10000): 8.499999967170879e-05\n",
      "Total time with cpu (100000000): 0.4272309999996651\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.4340970000002926\n",
      "Total time with cpu (10000): 9.799999952520011e-05\n",
      "Total time with cpu (100000000): 0.4388180000005377\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.44042999999965105\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.44027399999959016\n",
      "Total time with cpu (10000): 0.00024299999950017082\n",
      "Total time with cpu (100000000): 0.43557200000032026\n",
      "Total time with cpu (10000): 9.799999952520011e-05\n",
      "Total time with cpu (100000000): 0.4372480000001815\n",
      "Total time with cpu (10000): 9.299999965151073e-05\n",
      "Total time with cpu (100000000): 0.43942000000060943\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.4429579999996349\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.44048300000031304\n",
      "Total time with cpu (10000): 0.00010999999994965037\n",
      "Total time with cpu (100000000): 0.44401400000060676\n",
      "Total time with cpu (10000): 0.00010900000052060932\n",
      "Total time with cpu (100000000): 0.44434199999977864\n",
      "Total time with cpu (10000): 0.00010999999994965037\n",
      "Total time with cpu (100000000): 0.4478420000004917\n",
      "Total time with cpu (10000): 9.899999986373587e-05\n",
      "Total time with cpu (100000000): 0.43961600000056933\n",
      "Total time with cpu (10000): 9.59999997576233e-05\n",
      "Total time with cpu (100000000): 0.4400000000005093\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.42860300000029383\n",
      "Total time with cpu (10000): 8.69999994392856e-05\n",
      "Total time with cpu (100000000): 0.43128100000012637\n",
      "Total time with cpu (10000): 8.600000001024455e-05\n",
      "Total time with cpu (100000000): 0.42950999999993655\n",
      "Total time with cpu (10000): 0.00010399999973742524\n",
      "Total time with cpu (100000000): 0.4291350000003149\n",
      "Total time with cpu (10000): 8.69999994392856e-05\n",
      "Total time with cpu (100000000): 0.43867300000056275\n",
      "Total time with cpu (10000): 0.00010099999963131268\n",
      "Total time with cpu (100000000): 0.4320109999998749\n",
      "Total time with cpu (10000): 8.299999990413198e-05\n",
      "Total time with cpu (100000000): 0.4443229999997129\n",
      "Total time with cpu (10000): 0.00010000000020227162\n",
      "Total time with cpu (100000000): 0.44371199999932287\n",
      "Total time with cpu (10000): 9.800000043469481e-05\n",
      "Total time with cpu (100000000): 0.4440180000001419\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.43379800000002433\n",
      "Total time with cpu (10000): 9.700000009615906e-05\n",
      "Total time with cpu (100000000): 0.43624999999974534\n",
      "Total time with cpu (10000): 8.299999990413198e-05\n",
      "Total time with cpu (100000000): 0.44511400000010326\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.4452840000003562\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.44570500000008906\n",
      "Total time with cpu (10000): 9.300000056100544e-05\n",
      "Total time with cpu (100000000): 0.4440340000001015\n",
      "Total time with cpu (10000): 9.499999941908754e-05\n",
      "Total time with cpu (100000000): 0.4459969999998066\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.43413499999951455\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.43623999999999796\n",
      "Total time with cpu (10000): 9.700000009615906e-05\n",
      "Total time with cpu (100000000): 0.4308939999991708\n",
      "Total time with cpu (10000): 8.50000005812035e-05\n",
      "Total time with cpu (100000000): 0.4406069999995452\n",
      "Total time with cpu (10000): 0.0001049999991664663\n",
      "Total time with cpu (100000000): 0.4481450000002951\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4353420000006736\n",
      "Total time with cpu (10000): 8.799999977782136e-05\n",
      "Total time with cpu (100000000): 0.438083000000006\n",
      "Total time with cpu (10000): 9.899999986373587e-05\n",
      "Total time with cpu (100000000): 0.42803399999957037\n",
      "Total time with cpu (10000): 9.300000056100544e-05\n",
      "Total time with cpu (100000000): 0.4474479999998948\n",
      "Total time with cpu (10000): 0.00010600000041449675\n",
      "Total time with cpu (100000000): 0.45661399999971763\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.44904200000019046\n",
      "Total time with cpu (10000): 9.500000032858225e-05\n",
      "Total time with cpu (100000000): 0.4467500000000655\n",
      "Total time with cpu (10000): 8.69999994392856e-05\n",
      "Total time with cpu (100000000): 0.44171300000016345\n",
      "Total time with cpu (10000): 9.500000032858225e-05\n",
      "Total time with cpu (100000000): 0.44922500000029686\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.43180300000040006\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.44248400000014954\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.44696899999962625\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.4446349999998347\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.44235200000002806\n",
      "Total time with cpu (10000): 8.799999977782136e-05\n",
      "Total time with cpu (100000000): 0.44346799999948416\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4376379999994242\n",
      "Total time with cpu (10000): 7.699999969190685e-05\n",
      "Total time with cpu (100000000): 0.44827900000018417\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.4398490000003221\n",
      "Total time with cpu (10000): 8.299999990413198e-05\n",
      "Total time with cpu (100000000): 0.4382070000001477\n",
      "Total time with cpu (10000): 9.800000043469481e-05\n",
      "Total time with cpu (100000000): 0.4341789999998582\n",
      "Total time with cpu (10000): 8.70000003487803e-05\n",
      "Total time with cpu (100000000): 0.44606800000019575\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.4393679999993765\n",
      "Total time with cpu (10000): 9.900000077323057e-05\n",
      "Total time with cpu (100000000): 0.4298209999997198\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.43663800000013\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.4331060000004072\n",
      "Total time with cpu (10000): 8.799999977782136e-05\n",
      "Total time with cpu (100000000): 0.4373670000004495\n",
      "Total time with cpu (10000): 0.00010199999996984843\n",
      "Total time with cpu (100000000): 0.44444099999964237\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4411499999996522\n",
      "Total time with cpu (10000): 8.799999977782136e-05\n",
      "Total time with cpu (100000000): 0.4334150000004229\n",
      "Total time with cpu (10000): 0.00010999999994965037\n",
      "Total time with cpu (100000000): 0.4359580000000278\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.43143400000008114\n",
      "Total time with cpu (10000): 0.00020600000061676838\n",
      "Total time with cpu (100000000): 0.43234600000050705\n",
      "Total time with cpu (10000): 0.00011199999971722718\n",
      "Total time with cpu (100000000): 0.43440000000009604\n",
      "Total time with cpu (10000): 9.299999965151073e-05\n",
      "Total time with cpu (100000000): 0.43405000000075233\n",
      "Total time with cpu (10000): 8.600000001024455e-05\n",
      "Total time with cpu (100000000): 0.4325189999999566\n",
      "Total time with cpu (10000): 9.899999986373587e-05\n",
      "Total time with cpu (100000000): 0.43557700000019395\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4315820000001622\n",
      "Total time with cpu (10000): 9.299999965151073e-05\n",
      "Total time with cpu (100000000): 0.4375529999997525\n",
      "Total time with cpu (10000): 0.00010199999996984843\n",
      "Total time with cpu (100000000): 0.445451999999932\n",
      "Total time with cpu (10000): 0.00010300000030838419\n",
      "Total time with cpu (100000000): 0.43661599999995815\n",
      "Total time with cpu (10000): 9.700000009615906e-05\n",
      "Total time with cpu (100000000): 0.4403839999995398\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.43763699999999517\n",
      "Total time with cpu (10000): 9.899999986373587e-05\n",
      "Total time with cpu (100000000): 0.4425280000004932\n",
      "Total time with cpu (10000): 9.899999986373587e-05\n",
      "Total time with cpu (100000000): 0.439726999999948\n",
      "Total time with cpu (10000): 0.000113999999484804\n",
      "Total time with cpu (100000000): 0.43383300000004965\n",
      "Total time with cpu (10000): 9.499999941908754e-05\n",
      "Total time with cpu (100000000): 0.43665800000053423\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.44437899999957153\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.4451699999999619\n",
      "Total time with cpu (10000): 8.100000013655517e-05\n",
      "Total time with cpu (100000000): 0.44711199999983364\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.4414359999991575\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.44927000000006956\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.45030399999996007\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.4378310000001875\n",
      "Total time with cpu (10000): 8.299999990413198e-05\n",
      "Total time with cpu (100000000): 0.4488259999998263\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.4461029999993116\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.45020500000009633\n",
      "Total time with cpu (10000): 9.59999997576233e-05\n",
      "Total time with cpu (100000000): 0.44063699999969685\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.45156299999962357\n",
      "Total time with cpu (10000): 8.499999967170879e-05\n",
      "Total time with cpu (100000000): 0.44435799999973824\n",
      "Total time with cpu (10000): 8.70000003487803e-05\n",
      "Total time with cpu (100000000): 0.44814099999985046\n",
      "Total time with cpu (10000): 8.400000024266774e-05\n",
      "Total time with cpu (100000000): 0.4503130000002784\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4441470000001573\n",
      "Total time with cpu (10000): 9.199999931297498e-05\n",
      "Total time with cpu (100000000): 0.44471599999997125\n",
      "Total time with cpu (10000): 9.299999965151073e-05\n",
      "Total time with cpu (100000000): 0.44707300000027317\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.4424849999995786\n",
      "Total time with cpu (10000): 8.499999967170879e-05\n",
      "Total time with cpu (100000000): 0.4473779999998442\n",
      "Total time with cpu (10000): 9.700000009615906e-05\n",
      "Total time with cpu (100000000): 0.4435219999995752\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.4503210000002582\n",
      "Total time with cpu (10000): 9.299999965151073e-05\n",
      "Total time with cpu (100000000): 0.4442269999999553\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.4341949999998178\n",
      "Total time with cpu (10000): 9.899999986373587e-05\n",
      "Total time with cpu (100000000): 0.4319260000002032\n",
      "Total time with cpu (10000): 8.600000001024455e-05\n",
      "Total time with cpu (100000000): 0.44105799999942974\n",
      "Total time with cpu (10000): 9.700000009615906e-05\n",
      "Total time with cpu (100000000): 0.44855200000074547\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.44797600000038074\n",
      "Total time with cpu (10000): 9.59999997576233e-05\n",
      "Total time with cpu (100000000): 0.45052100000066275\n",
      "Total time with cpu (10000): 8.400000024266774e-05\n",
      "Total time with cpu (100000000): 0.44131600000036997\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4549269999997705\n",
      "Total time with cpu (10000): 9.800000043469481e-05\n",
      "Total time with cpu (100000000): 0.45183799999995244\n",
      "Total time with cpu (10000): 9.299999965151073e-05\n",
      "Total time with cpu (100000000): 0.4443249999994805\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.4451519999993252\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.4510580000005575\n",
      "Total time with cpu (10000): 8.799999977782136e-05\n",
      "Total time with cpu (100000000): 0.43760199999996985\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4357079999999769\n",
      "Total time with cpu (10000): 8.799999977782136e-05\n",
      "Total time with cpu (100000000): 0.4412979999997333\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.44519800000034593\n",
      "Total time with cpu (10000): 0.00010199999996984843\n",
      "Total time with cpu (100000000): 0.4456029999992097\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.43369299999994837\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.44896200000039244\n",
      "Total time with cpu (10000): 0.00011100000028818613\n",
      "Total time with cpu (100000000): 0.44258499999978085\n",
      "Total time with cpu (10000): 0.00010099999963131268\n",
      "Total time with cpu (100000000): 0.4501620000000912\n",
      "Total time with cpu (10000): 9.699999918666435e-05\n",
      "Total time with cpu (100000000): 0.4503979999999501\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.4428760000000693\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.4313139999994746\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.43673799999942275\n",
      "Total time with cpu (10000): 0.00010899999961111462\n",
      "Total time with cpu (100000000): 0.43116900000040914\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.4391190000005736\n",
      "Total time with cpu (10000): 9.299999965151073e-05\n",
      "Total time with cpu (100000000): 0.44504700000015873\n",
      "Total time with cpu (10000): 0.00010199999996984843\n",
      "Total time with cpu (100000000): 0.43363700000008976\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.44404800000029354\n",
      "Total time with cpu (10000): 8.799999977782136e-05\n",
      "Total time with cpu (100000000): 0.43526999999994587\n",
      "Total time with cpu (10000): 8.70000003487803e-05\n",
      "Total time with cpu (100000000): 0.43537300000025425\n",
      "Total time with cpu (10000): 9.6000000667118e-05\n",
      "Total time with cpu (100000000): 0.43941199999972014\n",
      "Total time with cpu (10000): 0.00010000000020227162\n",
      "Total time with cpu (100000000): 0.43278599999939615\n",
      "Total time with cpu (10000): 9.499999941908754e-05\n",
      "Total time with cpu (100000000): 0.43144200000006094\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.4475640000000567\n",
      "Total time with cpu (10000): 9.59999997576233e-05\n",
      "Total time with cpu (100000000): 0.4405399999996007\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.443025999999918\n",
      "Total time with cpu (10000): 8.69999994392856e-05\n",
      "Total time with cpu (100000000): 0.42842099999961647\n",
      "Total time with cpu (10000): 8.400000024266774e-05\n",
      "Total time with cpu (100000000): 0.43776100000013685\n",
      "Total time with cpu (10000): 8.899999920686241e-05\n",
      "Total time with cpu (100000000): 0.4409749999995256\n",
      "Total time with cpu (10000): 9.799999952520011e-05\n",
      "Total time with cpu (100000000): 0.4338739999993777\n",
      "Total time with cpu (10000): 0.001389000000017404\n",
      "Total time with cpu (100000000): 0.4330369999997856\n",
      "Total time with cpu (10000): 8.600000001024455e-05\n",
      "Total time with cpu (100000000): 0.43428899999980786\n",
      "Total time with cpu (10000): 8.69999994392856e-05\n",
      "Total time with cpu (100000000): 0.4347330000000511\n",
      "Total time with cpu (10000): 9.299999965151073e-05\n",
      "Total time with cpu (100000000): 0.4362879999998768\n",
      "Total time with cpu (10000): 8.199999956559623e-05\n",
      "Total time with cpu (100000000): 0.43862300000000687\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.43763900000067224\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.44668799999999464\n",
      "Total time with cpu (10000): 0.00010199999996984843\n",
      "Total time with cpu (100000000): 0.4482719999996334\n",
      "Total time with cpu (10000): 9.100000079342863e-05\n",
      "Total time with cpu (100000000): 0.4444180000000415\n",
      "Total time with cpu (10000): 9.299999965151073e-05\n",
      "Total time with cpu (100000000): 0.4454939999995986\n",
      "Total time with cpu (10000): 8.100000013655517e-05\n",
      "Total time with cpu (100000000): 0.4436020000002827\n",
      "Total time with cpu (10000): 9.500000032858225e-05\n",
      "Total time with cpu (100000000): 0.45085000000017317\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.45182199999999284\n",
      "Total time with cpu (10000): 9.100000079342863e-05\n",
      "Total time with cpu (100000000): 0.4447810000001482\n",
      "Total time with cpu (10000): 0.00010000000020227162\n",
      "Total time with cpu (100000000): 0.44690799999989395\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.4489819999998872\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.43713599999955477\n",
      "Total time with cpu (10000): 9.199999931297498e-05\n",
      "Total time with cpu (100000000): 0.441370000000461\n",
      "Total time with cpu (10000): 8.600000001024455e-05\n",
      "Total time with cpu (100000000): 0.4386770000000979\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.4483719999998357\n",
      "Total time with cpu (10000): 9.59999997576233e-05\n",
      "Total time with cpu (100000000): 0.44323199999962526\n",
      "Total time with cpu (10000): 9.6000000667118e-05\n",
      "Total time with cpu (100000000): 0.45162400000026537\n",
      "Total time with cpu (10000): 9.199999931297498e-05\n",
      "Total time with cpu (100000000): 0.4531349999997474\n",
      "Total time with cpu (10000): 9.300000056100544e-05\n",
      "Total time with cpu (100000000): 0.43570199999976467\n",
      "Total time with cpu (10000): 0.00010999999994965037\n",
      "Total time with cpu (100000000): 0.4361619999999675\n",
      "Total time with cpu (10000): 0.00010099999963131268\n",
      "Total time with cpu (100000000): 0.43459600000005594\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.4395759999997608\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.4401689999995142\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.4295849999998609\n",
      "Total time with cpu (10000): 0.00010000000020227162\n",
      "Total time with cpu (100000000): 0.4396969999997964\n",
      "Total time with cpu (10000): 0.000105000000075961\n",
      "Total time with cpu (100000000): 0.4302139999999781\n",
      "Total time with cpu (10000): 9.6000000667118e-05\n",
      "Total time with cpu (100000000): 0.429349999999431\n",
      "Total time with cpu (10000): 0.00010099999963131268\n",
      "Total time with cpu (100000000): 0.43795999999929336\n",
      "Total time with cpu (10000): 9.800000043469481e-05\n",
      "Total time with cpu (100000000): 0.43505199999981414\n",
      "Total time with cpu (10000): 9.699999918666435e-05\n",
      "Total time with cpu (100000000): 0.42954700000063895\n",
      "Total time with cpu (10000): 9.100000079342863e-05\n",
      "Total time with cpu (100000000): 0.4354380000004312\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.4401159999997617\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.44230100000004313\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.437525999999707\n",
      "Total time with cpu (10000): 9.100000079342863e-05\n",
      "Total time with cpu (100000000): 0.4376810000003388\n",
      "Total time with cpu (10000): 9.700000009615906e-05\n",
      "Total time with cpu (100000000): 0.4411340000006021\n",
      "Total time with cpu (10000): 9.899999986373587e-05\n",
      "Total time with cpu (100000000): 0.4406170000002021\n",
      "Total time with cpu (10000): 9.59999997576233e-05\n",
      "Total time with cpu (100000000): 0.42415100000016537\n",
      "Total time with cpu (10000): 0.000105000000075961\n",
      "Total time with cpu (100000000): 0.43731800000023213\n",
      "Total time with cpu (10000): 9.500000032858225e-05\n",
      "Total time with cpu (100000000): 0.43926099999953294\n",
      "Total time with cpu (10000): 9.799999952520011e-05\n",
      "Total time with cpu (100000000): 0.43836499999997613\n",
      "Total time with cpu (10000): 0.000105000000075961\n",
      "Total time with cpu (100000000): 0.44168900000022404\n",
      "Total time with cpu (10000): 8.50000005812035e-05\n",
      "Total time with cpu (100000000): 0.443384000000151\n",
      "Total time with cpu (10000): 9.300000056100544e-05\n",
      "Total time with cpu (100000000): 0.4329760000000533\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.4378710000000865\n",
      "Total time with cpu (10000): 9.59999997576233e-05\n",
      "Total time with cpu (100000000): 0.4372089999997115\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.43814300000030926\n",
      "Total time with cpu (10000): 0.00010099999963131268\n",
      "Total time with cpu (100000000): 0.4473439999992479\n",
      "Total time with cpu (10000): 8.399999933317304e-05\n",
      "Total time with cpu (100000000): 0.4422949999998309\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.4521649999996953\n",
      "Total time with cpu (10000): 9.300000056100544e-05\n",
      "Total time with cpu (100000000): 0.44149000000015803\n",
      "Total time with cpu (10000): 9.59999997576233e-05\n",
      "Total time with cpu (100000000): 0.4377169999997932\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.44405399999959627\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.44248500000048807\n",
      "Total time with cpu (10000): 9.699999918666435e-05\n",
      "Total time with cpu (100000000): 0.4271790000002511\n",
      "Total time with cpu (10000): 0.00010000000020227162\n",
      "Total time with cpu (100000000): 0.4350989999993544\n",
      "Total time with cpu (10000): 8.70000003487803e-05\n",
      "Total time with cpu (100000000): 0.4520730000003823\n",
      "Total time with cpu (10000): 9.199999931297498e-05\n",
      "Total time with cpu (100000000): 0.44856699999945704\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4441179999994347\n",
      "Total time with cpu (10000): 9.500000032858225e-05\n",
      "Total time with cpu (100000000): 0.44353399999999965\n",
      "Total time with cpu (10000): 8.600000001024455e-05\n",
      "Total time with cpu (100000000): 0.451640000000225\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4473279999992883\n",
      "Total time with cpu (10000): 8.600000001024455e-05\n",
      "Total time with cpu (100000000): 0.4471480000001975\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.4462410000005548\n",
      "Total time with cpu (10000): 9.700000009615906e-05\n",
      "Total time with cpu (100000000): 0.4476039999999557\n",
      "Total time with cpu (10000): 9.300000056100544e-05\n",
      "Total time with cpu (100000000): 0.4507869999997638\n",
      "Total time with cpu (10000): 8.799999977782136e-05\n",
      "Total time with cpu (100000000): 0.45023700000001554\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.4383379999999306\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.44059700000070734\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4469359999993685\n",
      "Total time with cpu (10000): 0.00010600000041449675\n",
      "Total time with cpu (100000000): 0.44397699999990436\n",
      "Total time with cpu (10000): 0.00010000000020227162\n",
      "Total time with cpu (100000000): 0.4417359999997643\n",
      "Total time with cpu (10000): 9.000000045489287e-05\n",
      "Total time with cpu (100000000): 0.44230400000014924\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.44476099999974394\n",
      "Total time with cpu (10000): 9.700000009615906e-05\n",
      "Total time with cpu (100000000): 0.4346270000005461\n",
      "Total time with cpu (10000): 0.00010000000020227162\n",
      "Total time with cpu (100000000): 0.4443090000004304\n",
      "Total time with cpu (10000): 9.300000056100544e-05\n",
      "Total time with cpu (100000000): 0.44287900000017544\n",
      "Total time with cpu (10000): 0.00010199999996984843\n",
      "Total time with cpu (100000000): 0.44321099999979197\n",
      "Total time with cpu (10000): 0.00010300000030838419\n",
      "Total time with cpu (100000000): 0.45077500000024884\n",
      "Total time with cpu (10000): 9.299999965151073e-05\n",
      "Total time with cpu (100000000): 0.4478870000002644\n",
      "Total time with cpu (10000): 8.499999967170879e-05\n",
      "Total time with cpu (100000000): 0.45153900000059366\n",
      "Total time with cpu (10000): 8.999999954539817e-05\n",
      "Total time with cpu (100000000): 0.4492360000003828\n",
      "Total time with cpu (10000): 0.00010000000020227162\n",
      "Total time with cpu (100000000): 0.44981599999937316\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.45337000000017724\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.43553700000029494\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.447692000000643\n",
      "Total time with cpu (10000): 8.499999967170879e-05\n",
      "Total time with cpu (100000000): 0.4483620000000883\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4391669999995429\n",
      "Total time with cpu (10000): 8.800000068731606e-05\n",
      "Total time with cpu (100000000): 0.4448110000002998\n",
      "Total time with cpu (10000): 9.700000009615906e-05\n",
      "Total time with cpu (100000000): 0.4489639999992505\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.44667799999933777\n",
      "Total time with cpu (10000): 9.299999965151073e-05\n",
      "Total time with cpu (100000000): 0.4435329999996611\n",
      "Total time with cpu (10000): 8.600000001024455e-05\n",
      "Total time with cpu (100000000): 0.4507149999999456\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.44904699999915465\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.445636999999806\n",
      "Total time with cpu (10000): 9.199999931297498e-05\n",
      "Total time with cpu (100000000): 0.4484780000002502\n",
      "Total time with cpu (10000): 9.199999931297498e-05\n",
      "Total time with cpu (100000000): 0.4307890000000043\n",
      "Total time with cpu (10000): 8.300000081362668e-05\n",
      "Total time with cpu (100000000): 0.4408630000007179\n",
      "Total time with cpu (10000): 8.499999967170879e-05\n",
      "Total time with cpu (100000000): 0.45021300000007614\n",
      "Total time with cpu (10000): 9.59999997576233e-05\n",
      "Total time with cpu (100000000): 0.4424330000001646\n",
      "Total time with cpu (10000): 8.70000003487803e-05\n",
      "Total time with cpu (100000000): 0.446763999999348\n",
      "Total time with cpu (10000): 8.400000024266774e-05\n",
      "Total time with cpu (100000000): 0.4371069999997417\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.4445979999991323\n",
      "Total time with cpu (10000): 8.100000013655517e-05\n",
      "Total time with cpu (100000000): 0.4476469999999608\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.4469219999991765\n",
      "Total time with cpu (10000): 9.300000056100544e-05\n",
      "Total time with cpu (100000000): 0.4467260000001261\n",
      "Total time with cpu (10000): 0.00010000000020227162\n",
      "Total time with cpu (100000000): 0.4377359999998589\n",
      "Total time with cpu (10000): 8.399999933317304e-05\n",
      "Total time with cpu (100000000): 0.4373990000003687\n",
      "Total time with cpu (10000): 8.70000003487803e-05\n",
      "Total time with cpu (100000000): 0.4364079999995738\n",
      "Total time with cpu (10000): 8.499999967170879e-05\n",
      "Total time with cpu (100000000): 0.44739899999967747\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.44147400000019843\n",
      "Total time with cpu (10000): 9.499999941908754e-05\n",
      "Total time with cpu (100000000): 0.4385940000001938\n",
      "Total time with cpu (10000): 8.70000003487803e-05\n",
      "Total time with cpu (100000000): 0.43726299999980256\n",
      "Total time with cpu (10000): 8.600000001024455e-05\n",
      "Total time with cpu (100000000): 0.43910700000014913\n",
      "Total time with cpu (10000): 0.00010000000020227162\n",
      "Total time with cpu (100000000): 0.4391810000006444\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.44696399999975256\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.4391459999997096\n",
      "Total time with cpu (10000): 8.400000024266774e-05\n",
      "Total time with cpu (100000000): 0.4477200000001176\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.44375100000070233\n",
      "Total time with cpu (10000): 8.299999990413198e-05\n",
      "Total time with cpu (100000000): 0.4476969999996072\n",
      "Total time with cpu (10000): 8.400000024266774e-05\n",
      "Total time with cpu (100000000): 0.44826999999986583\n",
      "Total time with cpu (10000): 9.299999965151073e-05\n",
      "Total time with cpu (100000000): 0.45407999999952153\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.4462789999997767\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.44343299999945884\n",
      "Total time with cpu (10000): 0.00010199999996984843\n",
      "Total time with cpu (100000000): 0.44967299999916577\n",
      "Total time with cpu (10000): 9.800000043469481e-05\n",
      "Total time with cpu (100000000): 0.4487279999993916\n",
      "Total time with cpu (10000): 8.200000047509093e-05\n",
      "Total time with cpu (100000000): 0.43814500000007683\n",
      "Total time with cpu (10000): 8.70000003487803e-05\n",
      "Total time with cpu (100000000): 0.44214300000021467\n",
      "Total time with cpu (10000): 8.300000081362668e-05\n",
      "Total time with cpu (100000000): 0.4343280000002778\n",
      "Total time with cpu (10000): 8.200000047509093e-05\n",
      "Total time with cpu (100000000): 0.4406699999999546\n",
      "Total time with cpu (10000): 8.50000005812035e-05\n",
      "Total time with cpu (100000000): 0.4460269999999582\n",
      "Total time with cpu (10000): 8.900000011635711e-05\n",
      "Total time with cpu (100000000): 0.43851600000016333\n",
      "Total time with cpu (10000): 8.299999990413198e-05\n",
      "Total time with cpu (100000000): 0.44032100000003993\n",
      "Total time with cpu (10000): 8.499999967170879e-05\n",
      "Total time with cpu (100000000): 0.4381870000006529\n",
      "Total time with cpu (10000): 8.899999920686241e-05\n",
      "Total time with cpu (100000000): 0.4450189999997747\n",
      "Total time with cpu (10000): 9.499999941908754e-05\n",
      "Total time with cpu (100000000): 0.4441259999994145\n",
      "Total time with cpu (10000): 8.69999994392856e-05\n",
      "Total time with cpu (100000000): 0.43607500000052823\n",
      "Total time with cpu (10000): 8.800000068731606e-05\n",
      "Total time with cpu (100000000): 0.4369540000006964\n",
      "Total time with cpu (10000): 9.100000079342863e-05\n",
      "Total time with cpu (100000000): 0.44112700000005134\n",
      "Total time with cpu (10000): 9.399999999004649e-05\n",
      "Total time with cpu (100000000): 0.4306720000004134\n",
      "Total time with cpu (10000): 9.59999997576233e-05\n",
      "Total time with cpu (100000000): 0.4355329999998503\n",
      "Total time with cpu (10000): 9.200000022246968e-05\n",
      "Total time with cpu (100000000): 0.44400299999961135\n",
      "Total time with cpu (10000): 0.00010900000052060932\n",
      "Total time with cpu (100000000): 0.4489159999993717\n",
      "Total time with cpu (10000): 8.800000068731606e-05\n",
      "Total time with cpu (100000000): 0.4465220000001864\n",
      "Total time with cpu (10000): 0.00010300000030838419\n",
      "Total time with cpu (100000000): 0.4467080000003989\n",
      "Total time with cpu (10000): 9.499999941908754e-05\n",
      "Total time with cpu (100000000): 0.4535459999997329\n",
      "Total time with cpu (10000): 9.59999997576233e-05\n",
      "Total time with cpu (100000000): 0.44091800000023795\n",
      "Total time with cpu (10000): 7.59999993533711e-05\n",
      "Total time with cpu (100000000): 0.4385050000000774\n",
      "Total time with cpu (10000): 8.100000013655517e-05\n",
      "Total time with cpu (100000000): 0.43988900000022113\n",
      "Total time with cpu (10000): 8.499999967170879e-05\n",
      "Total time with cpu (100000000): 0.44087500000023283\n",
      "Total time with cpu (10000): 8.299999990413198e-05\n",
      "Total time with cpu (100000000): 0.4417169999996986\n",
      "Total time with cpu (10000): 9.099999988393392e-05\n",
      "Total time with cpu (100000000): 0.44317599999976665\n",
      "Total time with cpu (10000): 9.899999986373587e-05\n",
      "Total time with cpu (100000000): 0.4436459999997169\n",
      "Total time with cpu (10000): 8.800000068731606e-05\n",
      "Total time with cpu (100000000): 0.4264680000005683\n",
      "Total time with cpu (10000): 9.799999952520011e-05\n",
      "Total time with cpu (100000000): 0.44631699999990815\n",
      "Total time with cpu (10000): 8.600000001024455e-05\n",
      "Total time with cpu (100000000): 0.4433070000004591\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m n2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000000\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n1):\n\u001b[0;32m---> 34\u001b[0m     testcpu()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n1):\n\u001b[1;32m     36\u001b[0m     testgpu()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import process_time\n",
    "import torch\n",
    "\n",
    "def testgpu():\n",
    "    if torch.backends.mps.is_available():\n",
    "        mps_device = torch.device(\"mps\")\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n1, device=mps_device)\n",
    "    y = x + torch.rand(n1, device=mps_device)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with gpu ({n1}): {t1-t0}\")\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n2, device=mps_device)\n",
    "    y = x + torch.rand(n2, device=mps_device)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with gpu ({n2}): {t1-t0}\")\n",
    "\n",
    "def testcpu():\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n1)\n",
    "    y = x + torch.rand(n1)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with cpu ({n1}): {t1-t0}\")\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n2)\n",
    "    y = x + torch.rand(n2)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with cpu ({n2}): {t1-t0}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n1 = 10000\n",
    "    n2 = 100000000\n",
    "    for x in range(n1):\n",
    "        testcpu()\n",
    "    for x in range(n1):\n",
    "        testgpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4f87a85-1796-4c94-b6e4-6825649475e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms # use v2 transforms for faster augmentations\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from tqdm.auto import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464e9a1-c940-4a09-b3ee-da27a16661b3",
   "metadata": {},
   "source": [
    "As this was a command line function, need some modifications to make it work in a notebook.\n",
    "See: https://stackoverflow.com/questions/48796169/how-to-fix-ipykernel-launcher-py-error-unrecognized-arguments-in-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c89cd60f-bb96-4796-b6eb-2e03c00d3193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15.2a0\n"
     ]
    }
   ],
   "source": [
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf2eb66-e465-4b15-8666-60c1d109c5bb",
   "metadata": {},
   "source": [
    "Latest version of torchvision is 0.17, but I can't convince conda to install that...\n",
    "https://pytorch.org/vision/0.15/transforms.html#transforms-scriptability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ea1d079-334e-452a-a8c7-29fb041851a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create DataLoaders\n",
    "    def create_dataloaders(batch_size, num_workers=NUM_WORKERS):\n",
    "        train_dataloader = DataLoader(train_data,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=num_workers,\n",
    "                                      pin_memory=False) # note: if you pin memory, you may get \"too many workers\" errors when recreating DataLoaders, see: https://github.com/Lightning-AI/pytorch-lightning/issues/18487#issuecomment-1740244601\n",
    "\n",
    "        test_dataloader = DataLoader(test_data,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=num_workers,\n",
    "                                     pin_memory=False)\n",
    "\n",
    "        return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "46ad373e-fe5f-4cbc-98eb-933f1a1981a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    ### Train Step ###\n",
    "    def train_step(model: torch.nn.Module, \n",
    "                   dataloader: torch.utils.data.DataLoader, \n",
    "                   loss_fn: torch.nn.Module, \n",
    "                   optimizer: torch.optim.Optimizer,\n",
    "                   device: torch.device):\n",
    "        # Put model in train mode\n",
    "        model.train()\n",
    "        \n",
    "        # Setup train loss and train accuracy values\n",
    "        train_loss, train_acc = 0, 0\n",
    "        \n",
    "        # Loop through data loader data batches\n",
    "        for batch, (X, y) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            # Send data to target device\n",
    "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "    #         X, y = X.to(device, non_blocking=True, memory_format=torch.channels_last), y.to(device, non_blocking=True)\n",
    "    #         X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # 2. Calculate  and accumulate loss\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            train_loss += loss.item() \n",
    "\n",
    "            # 3. Optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 4. Loss backward\n",
    "            loss.backward()\n",
    "\n",
    "            # 5. Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate and accumulate accuracy metric across all batches\n",
    "            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "            train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "            \n",
    "        # Adjust metrics to get average loss and accuracy per batch \n",
    "        train_loss = train_loss / len(dataloader)\n",
    "        train_acc = train_acc / len(dataloader)\n",
    "        return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6afa341a-d770-4601-9354-edccc144a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    ### Test Step ###\n",
    "    def test_step(model: torch.nn.Module, \n",
    "                dataloader: torch.utils.data.DataLoader, \n",
    "                loss_fn: torch.nn.Module,\n",
    "                device: torch.device):\n",
    "        # Put model in eval mode\n",
    "        model.eval() \n",
    "        \n",
    "        # Setup test loss and test accuracy values\n",
    "        test_loss, test_acc = 0, 0\n",
    "        \n",
    "        # Turn on inference context manager\n",
    "        with torch.inference_mode():\n",
    "            # Loop through DataLoader batches\n",
    "            for batch, (X, y) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "                # Send data to target device\n",
    "                X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "    #             X, y = X.to(device, non_blocking=True, memory_format=torch.channels_last), y.to(device, non_blocking=True)\n",
    "    #             X, y = X.to(device), y.to(device)\n",
    "        \n",
    "                # 1. Forward pass\n",
    "                test_pred_logits = model(X)\n",
    "\n",
    "                # 2. Calculate and accumulate loss\n",
    "                loss = loss_fn(test_pred_logits, y)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                # Calculate and accumulate accuracy\n",
    "                test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "                test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "                \n",
    "        # Adjust metrics to get average loss and accuracy per batch \n",
    "        test_loss = test_loss / len(dataloader)\n",
    "        test_acc = test_acc / len(dataloader)\n",
    "        return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7ee7266-5831-4dc8-b61a-8afb2f0ef2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train_and_time(batch_sizes=BATCH_SIZES,\n",
    "                       epochs=EPOCHS,\n",
    "                       device=device):\n",
    "\n",
    "        batch_size_training_results = []\n",
    "\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"[INFO] Training with batch size {batch_size} for {epochs} epochs...\")\n",
    "            # Create an instance of resnet50\n",
    "            model = torchvision.models.resnet50(num_classes=100).to(device)\n",
    "            # model = torch.compile(model) # potential way to speed up model\n",
    "\n",
    "            # Setup loss function and optimizer\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "\n",
    "            # Create DataLoaders\n",
    "            train_dataloader, test_dataloader = create_dataloaders(batch_size=batch_size)\n",
    "\n",
    "            try:\n",
    "                # Start the timer\n",
    "                start_time = timer()\n",
    "\n",
    "                # Train model\n",
    "                model_results = train_and_test_model(model=model, \n",
    "                                                    train_dataloader=train_dataloader,\n",
    "                                                    test_dataloader=test_dataloader,\n",
    "                                                    optimizer=optimizer,\n",
    "                                                    loss_fn=loss_fn, \n",
    "                                                    epochs=epochs,\n",
    "                                                    device=device,\n",
    "                                                    eval=False) # don't eval, just test training time\n",
    "\n",
    "                # End the timer\n",
    "                end_time = timer()\n",
    "\n",
    "                total_training_time = end_time - start_time\n",
    "                avg_time_per_epoch = total_training_time / epochs\n",
    "\n",
    "                batch_size_training_results.append({\"batch_size\": batch_size,\n",
    "                                                    \"avg_time_per_epoch\": avg_time_per_epoch})\n",
    "                save_results(batch_size_training_results)\n",
    "                print(f\"[INFO] Finished training with batch size {batch_size} for {epochs} epochs, total time: {round(total_training_time, 3)} seconds, avg time per epoch: {round(avg_time_per_epoch, 3)} seconds\\n\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[INFO] Error: {e}\")\n",
    "                print(f\"[INFO] Failed training with batch size {batch_size} for {epochs} epochs...\\n\\n\")\n",
    "                batch_size_training_results.append({\"batch_size\": batch_size,\n",
    "                                                    \"avg_time_per_epoch\": \"FAILED\"})\n",
    "                save_results(batch_size_training_results)\n",
    "                break\n",
    "                \n",
    "        return batch_size_training_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f1aab83-3060-4a65-8c7b-9c4023527df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    def save_results(batch_size_training_results, target_dir=\"results_pytorch_cv\"):\n",
    "        # Create CSV filename\n",
    "        if GPU_NAME:\n",
    "            csv_filename = f\"{GPU_NAME.replace(' ', '_')}_{DATASET_NAME}_{MODEL_NAME}_{INPUT_SHAPE[-1]}_{BACKEND}_results.csv\"\n",
    "        else:\n",
    "            csv_filename = f\"{CPU_PROCESSOR}_{DATASET_NAME}_{MODEL_NAME}_{INPUT_SHAPE[-1]}_{BACKEND}_results.csv\"\n",
    "\n",
    "        # Make the target results directory if it doesn't exist (include the parents)\n",
    "        target_results_dir = target_dir\n",
    "        results_path = Path(\"results\") / target_results_dir\n",
    "        results_path.mkdir(parents=True, exist_ok=True)\n",
    "        csv_filepath = results_path / csv_filename\n",
    "\n",
    "        # Turn dict into DataFrame \n",
    "        df = pd.DataFrame(batch_size_training_results) \n",
    "\n",
    "        # Save to CSV\n",
    "        print(f\"[INFO] Saving results to: {csv_filepath}\")\n",
    "        df.to_csv(csv_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c2d50bce-d7cc-48cb-a4e6-66bed582c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 1. Take in various parameters required for training and test steps\n",
    "    def train_and_test_model(model: torch.nn.Module, \n",
    "                            train_dataloader: torch.utils.data.DataLoader, \n",
    "                            test_dataloader: torch.utils.data.DataLoader, \n",
    "                            optimizer: torch.optim.Optimizer,\n",
    "                            loss_fn: torch.nn.Module,\n",
    "                            epochs: int,\n",
    "                            device: torch.device,\n",
    "                            eval: bool=False):\n",
    "        \n",
    "        print(f\"[INFO] Training model {model.__class__.__name__} on device '{device}' for {epochs} epochs...\")\n",
    "        \n",
    "        results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
    "\n",
    "        # Loop through training and testing steps for a number of epochs\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            # Do eval before training (to see if there's any errors)\n",
    "            if eval:\n",
    "                test_loss, test_acc = test_step(model=model,\n",
    "                                            dataloader=test_dataloader,\n",
    "                                            loss_fn=loss_fn,\n",
    "                                            device=device)\n",
    "            \n",
    "            train_loss, train_acc = train_step(model=model,\n",
    "                                            dataloader=train_dataloader,\n",
    "                                            loss_fn=loss_fn,\n",
    "                                            optimizer=optimizer,\n",
    "                                            device=device)\n",
    "            \n",
    "            \n",
    "            # Print out what's happening\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} | \"\n",
    "                f\"train_loss: {train_loss:.4f} | \"\n",
    "                f\"train_acc: {train_acc:.4f} | \"\n",
    "            )\n",
    "\n",
    "            if eval:\n",
    "                print(\n",
    "                    f\"Epoch: {epoch+1} | \"\n",
    "                    f\"test_loss: {test_loss:.4f} | \"\n",
    "                    f\"test_acc: {test_acc:.4f} | \"\n",
    "                )\n",
    "\n",
    "            # Save results to dictionary\n",
    "            results[\"train_loss\"].append(train_loss)\n",
    "            results[\"train_acc\"].append(train_acc)\n",
    "            if eval:\n",
    "                results[\"test_loss\"].append(test_loss)\n",
    "                results[\"test_acc\"].append(test_acc)\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0a93eba-1d6e-49bf-b8a4-1cb31ae0ceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] CPU Processor: Apple_M1_Max\n",
      "[INFO] MPS device found, using device: mps\n",
      "[INFO] Testing model: resnet50 on CIFAR100 dataset with input shape (3, 32, 32) for 5 epochs across batch sizes: [16, 32, 64, 128, 256, 512, 1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[INFO] Number of training samples: 50000, number of testing samples: 10000\n",
      "[INFO] Training with batch size 16 for 5 epochs...\n",
      "[INFO] Training model ResNet on device 'mps' for 5 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fc5d6c262b465d88f3ec627d98f3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py:222: UserWarning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712648268885/work/aten/src/ATen/ParallelNative.cpp:228.)\n",
      "  torch.set_num_threads(1)\n",
      "/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py:222: UserWarning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712648268885/work/aten/src/ATen/ParallelNative.cpp:228.)\n",
      "  torch.set_num_threads(1)\n",
      "/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py:222: UserWarning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712648268885/work/aten/src/ATen/ParallelNative.cpp:228.)\n",
      "  torch.set_num_threads(1)\n",
      "/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py:222: UserWarning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712648268885/work/aten/src/ATen/ParallelNative.cpp:228.)\n",
      "  torch.set_num_threads(1)\n",
      "/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py:222: UserWarning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712648268885/work/aten/src/ATen/ParallelNative.cpp:228.)\n",
      "  torch.set_num_threads(1)\n",
      "/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py:222: UserWarning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712648268885/work/aten/src/ATen/ParallelNative.cpp:228.)\n",
      "  torch.set_num_threads(1)\n",
      "/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py:222: UserWarning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712648268885/work/aten/src/ATen/ParallelNative.cpp:228.)\n",
      "  torch.set_num_threads(1)\n",
      "/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py:222: UserWarning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712648268885/work/aten/src/ATen/ParallelNative.cpp:228.)\n",
      "  torch.set_num_threads(1)\n",
      "/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py:222: UserWarning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712648268885/work/aten/src/ATen/ParallelNative.cpp:228.)\n",
      "  torch.set_num_threads(1)\n",
      "/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py:222: UserWarning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1712648268885/work/aten/src/ATen/ParallelNative.cpp:228.)\n",
      "  torch.set_num_threads(1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b59610b84242e1829b37a4820a6254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/rc/mdny9tkx4fzfdtr0kdhl5j540000gn/T/ipykernel_68969/1128608748.py\", line 69, in <module>\n",
      "    batch_size_training_results = train_and_time(batch_sizes=BATCH_SIZES,\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/rc/mdny9tkx4fzfdtr0kdhl5j540000gn/T/ipykernel_68969/4130627343.py\", line 25, in train_and_time\n",
      "    model_results = train_and_test_model(model=model,\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/rc/mdny9tkx4fzfdtr0kdhl5j540000gn/T/ipykernel_68969/2430635053.py\", line 24, in train_and_test_model\n",
      "    train_loss, train_acc = train_step(model=model,\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/rc/mdny9tkx4fzfdtr0kdhl5j540000gn/T/ipykernel_68969/3617347480.py\", line 31, in train_step\n",
      "    loss.backward()\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/_tensor.py\", line 534, in backward\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "    tensors,\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/torch/autograd/graph.py\", line 767, in _engine_run_backward\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/Users/rff/anaconda3/envs/MacML/lib/python3.11/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    CPU_PROCESSOR = None\n",
    "\n",
    "    ### Get CPU Processor name ###\n",
    "    if not CPU_PROCESSOR:\n",
    "        try:\n",
    "            import cpuinfo\n",
    "            CPU_PROCESSOR = cpuinfo.get_cpu_info().get(\"brand_raw\").replace(\" \", \"_\")\n",
    "            print(f\"[INFO] CPU Processor: {CPU_PROCESSOR}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}, may have failed to get CPU_PROCESSOR name from cpuinfo, please install cpuinfo or set CPU_PROCESSOR manually\") \n",
    "\n",
    "    ### Setup device ###\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(f\"[INFO] MPS device found, using device: {device}\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"[INFO] CUDA device found, using device: {device}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print (f\"[INFO] MPS or CUDA device not found, using device: {device} (results will be much slower than using MPS or CUDA)\")\n",
    "\n",
    "    # Prevent torch from erroring with too many files open (happens on M3)\n",
    "    # See: https://github.com/pytorch/pytorch/issues/11201, https://github.com/CVMI-Lab/PLA/issues/20 \n",
    "    torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "    # Set random seed\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    ### Set constants ###\n",
    "    GPU_NAME = \"mps\"\n",
    "    BACKEND = \"pytorch\"\n",
    "    MODEL_NAME = \"resnet50\"\n",
    "    IMAGE_SIZE = 32\n",
    "    INPUT_SHAPE = (3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    NUM_WORKERS = os.cpu_count()\n",
    "    EPOCHS = 5\n",
    "    BATCH_SIZES = [16, 32, 64, 128, 256, 512, 1024]\n",
    "    DATASET_NAME = \"CIFAR100\"\n",
    "\n",
    "    print(f\"[INFO] Testing model: {MODEL_NAME} on {DATASET_NAME} dataset with input shape {INPUT_SHAPE} for {EPOCHS} epochs across batch sizes: {BATCH_SIZES}\")\n",
    "\n",
    "\n",
    "    ### Prepare Data ### \n",
    "    simple_transform = transforms.Compose([\n",
    "        transforms.Resize(size=IMAGE_SIZE),\n",
    "        # for torchvision 0.15 I believe ToImage must be ToTensor\n",
    "        transforms.ToTensor(), \n",
    "        # again, since I seems stuck on 0.15, where there is no scale option\n",
    "        #transforms.ToDtype(torch.float32, scale=True)\n",
    "        transforms.ConvertDtype(torch.float32)\n",
    "\n",
    "    ])\n",
    "\n",
    "    # Get Datasets\n",
    "    train_data = datasets.CIFAR10(root=\"data\",\n",
    "                                train=True,\n",
    "                                transform=simple_transform,\n",
    "                                download=True)\n",
    "\n",
    "    test_data = datasets.CIFAR10(root=\"data\",\n",
    "                                train=False,\n",
    "                                transform=simple_transform,\n",
    "                                download=True)\n",
    "\n",
    "    print(f\"[INFO] Number of training samples: {len(train_data)}, number of testing samples: {len(test_data)}\")\n",
    "\n",
    "    ### Train an time model ### \n",
    "    batch_size_training_results = train_and_time(batch_sizes=BATCH_SIZES,\n",
    "                                                 epochs=EPOCHS,\n",
    "                                                 device=device)\n",
    "\n",
    "    print(\"[INFO] Finished training with all batch sizes.\")        \n",
    "\n",
    "    print(f\"[INFO] Results:\\n{batch_size_training_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff803b-a20a-4ea0-af1f-29103706c1a4",
   "metadata": {},
   "source": [
    "##Final Results##\n",
    "\n",
    "These results of this test appear to be twice as slow, running on an M1 Pro, as the original source demonstrated:\n",
    "\n",
    "[{'batch_size': 16, 'avg_time_per_epoch': 407.5454948831815}, {'batch_size': 32, 'avg_time_per_epoch': 233.77520572501234}, {'batch_size': 64, 'avg_time_per_epoch': 150.9472023168113}, {'batch_size': 128, 'avg_time_per_epoch': 109.9742384667974}, {'batch_size': 256, 'avg_time_per_epoch': 92.17897170837969}, {'batch_size': 512, 'avg_time_per_epoch': 91.76529929162935}, {'batch_size': 1024, 'avg_time_per_epoch': 91.80344411660917}]\n",
    "\n",
    "https://github.com/mrdbourke/mac-ml-speed-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0c0b7-3a17-430e-bce4-2f2b48aaf952",
   "metadata": {},
   "outputs": [],
   "source": [
    "??transforms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
