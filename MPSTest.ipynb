{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cfe85ff-060d-4e0e-8dd6-fba5e21f408a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device = mps_device)\n",
    "    print(x)\n",
    "else:\n",
    "    print(\"MPS device not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca5a4c49-367d-4b1c-8643-7d4254265d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00017679110169410706"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "import random\n",
    "\n",
    "x = torch.ones(500000000, device='mps')\n",
    "timeit.timeit(lambda:x * random.randint(0, 100), number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84edd018-7ed8-4df5-859b-25f56f63b300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0097809589933604"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(50000000, device=\"cpu\")\n",
    "timeit.timeit(lambda:x * random.randint(0,100), number = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7bd44a-a08c-4817-aa36-3775bde92c82",
   "metadata": {},
   "source": [
    "There definitely is a time difference, but the source I am comparing this to had 0.0003982 and 0.0112392, so overall the numbers I am seeing are off by a bit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a281d26a-1514-4547-b1a6-7d653434e58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time with cpu (10000): 0.0010329999999996176\n",
      "Total time with cpu (100000000): 0.5900970000000001\n",
      "Total time with gpu (10000): 0.012586000000000652\n",
      "Total time with gpu (100000000): 0.006569000000000713\n"
     ]
    }
   ],
   "source": [
    "from time import process_time\n",
    "import torch\n",
    "\n",
    "def testgpu():\n",
    "    if torch.backends.mps.is_available():\n",
    "        mps_device = torch.device(\"mps\")\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n1, device=mps_device)\n",
    "    y = x + torch.rand(n1, device=mps_device)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with gpu ({n1}): {t1-t0}\")\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n2, device=mps_device)\n",
    "    y = x + torch.rand(n2, device=mps_device)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with gpu ({n2}): {t1-t0}\")\n",
    "\n",
    "def testcpu():\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n1)\n",
    "    y = x + torch.rand(n1)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with cpu ({n1}): {t1-t0}\")\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n2)\n",
    "    y = x + torch.rand(n2)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with cpu ({n2}): {t1-t0}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n1 = 10000\n",
    "    n2 = 100000000\n",
    "    testcpu()\n",
    "    testgpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b343da6-c5f1-496a-8098-df01aa0ec7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.3.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/rff/anaconda3/envs/MacML\n",
      "\n",
      "  added / updated specs:\n",
      "    - jupyterlab\n",
      "    - langchain\n",
      "    - matplotlib\n",
      "    - numpy\n",
      "    - pandas\n",
      "    - pip\n",
      "    - prettytable\n",
      "    - py-cpuinfo\n",
      "    - scikit-learn\n",
      "    - tqdm\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    aiohttp-3.9.3              |  py311h80987f9_0         799 KB\n",
      "    aiosignal-1.3.1            |     pyhd8ed1ab_0          12 KB  conda-forge\n",
      "    annotated-types-0.6.0      |     pyhd8ed1ab_0          17 KB  conda-forge\n",
      "    async-timeout-4.0.3        |     pyhd8ed1ab_0          11 KB  conda-forge\n",
      "    bottleneck-1.3.7           |  py311hb9f6ed7_0         128 KB\n",
      "    brotli-1.1.0               |       hb547adb_1          19 KB  conda-forge\n",
      "    brotli-bin-1.1.0           |       hb547adb_1          17 KB  conda-forge\n",
      "    ca-certificates-2024.2.2   |       hf0a4a13_0         152 KB  conda-forge\n",
      "    certifi-2024.2.2           |     pyhd8ed1ab_0         157 KB  conda-forge\n",
      "    colorama-0.4.6             |     pyhd8ed1ab_0          25 KB  conda-forge\n",
      "    contourpy-1.2.0            |  py311h48ca7d4_0         255 KB\n",
      "    cycler-0.12.1              |     pyhd8ed1ab_0          13 KB  conda-forge\n",
      "    dataclasses-json-0.6.4     |     pyhd8ed1ab_0          29 KB  conda-forge\n",
      "    frozenlist-1.4.0           |  py311h80987f9_0          48 KB\n",
      "    greenlet-3.0.1             |  py311h313beb8_0         225 KB\n",
      "    importlib-metadata-7.1.0   |     pyha770c72_0          26 KB  conda-forge\n",
      "    importlib_metadata-7.1.0   |       hd8ed1ab_0           9 KB  conda-forge\n",
      "    importlib_resources-6.4.0  |     pyhd8ed1ab_0          32 KB  conda-forge\n",
      "    joblib-1.4.0               |     pyhd8ed1ab_0         215 KB  conda-forge\n",
      "    jsonpatch-1.33             |     pyhd8ed1ab_0          17 KB  conda-forge\n",
      "    jsonpointer-2.0            |             py_0           9 KB  conda-forge\n",
      "    jupyterlab-4.0.9           |     pyhd8ed1ab_0         5.1 MB  conda-forge\n",
      "    langchain-0.1.15           |     pyhd8ed1ab_0         421 KB  conda-forge\n",
      "    langchain-community-0.0.32 |     pyhd8ed1ab_0         905 KB  conda-forge\n",
      "    langchain-core-0.1.42      |     pyhd8ed1ab_0         186 KB  conda-forge\n",
      "    langchain-text-splitters-0.0.1|     pyhd8ed1ab_0          23 KB  conda-forge\n",
      "    langsmith-0.1.45           |     pyhd8ed1ab_0          85 KB  conda-forge\n",
      "    libbrotlicommon-1.1.0      |       hb547adb_1          67 KB  conda-forge\n",
      "    libbrotlidec-1.1.0         |       hb547adb_1          28 KB  conda-forge\n",
      "    libbrotlienc-1.1.0         |       hb547adb_1         274 KB  conda-forge\n",
      "    marshmallow-3.21.1         |     pyhd8ed1ab_0          90 KB  conda-forge\n",
      "    matplotlib-3.8.0           |  py311hca03da5_0           9 KB\n",
      "    matplotlib-base-3.8.0      |  py311h7aedaa7_0         7.7 MB\n",
      "    multidict-6.0.4            |  py311h80987f9_0          54 KB\n",
      "    munkres-1.1.4              |     pyh9f0ad1d_0          12 KB  conda-forge\n",
      "    mypy_extensions-1.0.0      |     pyha770c72_0          10 KB  conda-forge\n",
      "    numexpr-2.8.7              |  py311h6dc990b_0         151 KB\n",
      "    openssl-3.2.1              |       h0d3ecfb_1         2.7 MB  conda-forge\n",
      "    orjson-3.9.15              |  py311hc9796cf_0         261 KB\n",
      "    pandas-2.2.1               |  py311h7aedaa7_0        15.0 MB\n",
      "    pip-24.0                   |     pyhd8ed1ab_0         1.3 MB  conda-forge\n",
      "    prettytable-3.10.0         |     pyhd8ed1ab_0          29 KB  conda-forge\n",
      "    py-cpuinfo-9.0.0           |     pyhd8ed1ab_0          24 KB  conda-forge\n",
      "    pydantic-2.5.3             |     pyhd8ed1ab_0         256 KB  conda-forge\n",
      "    pydantic-core-2.14.6       |  py311hf0e4da2_0         1.6 MB\n",
      "    pyparsing-3.0.9            |     pyhd8ed1ab_0          79 KB  conda-forge\n",
      "    python-tzdata-2024.1       |     pyhd8ed1ab_0         141 KB  conda-forge\n",
      "    scikit-learn-1.2.2         |  py311h313beb8_1         8.2 MB\n",
      "    scipy-1.12.0               |  py311hc76d9b0_0        22.8 MB\n",
      "    sqlalchemy-2.0.25          |  py311h80987f9_0         3.8 MB\n",
      "    tenacity-8.2.3             |     pyhd8ed1ab_0          22 KB  conda-forge\n",
      "    threadpoolctl-3.4.0        |     pyhc1e730c_0          22 KB  conda-forge\n",
      "    tomli-2.0.1                |     pyhd8ed1ab_0          16 KB  conda-forge\n",
      "    tqdm-4.66.2                |     pyhd8ed1ab_0          87 KB  conda-forge\n",
      "    typing_inspect-0.9.0       |     pyhd8ed1ab_0          15 KB  conda-forge\n",
      "    yarl-1.9.3                 |  py311h80987f9_0         118 KB\n",
      "    zipp-3.17.0                |     pyhd8ed1ab_0          19 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        73.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  aiohttp            pkgs/main/osx-arm64::aiohttp-3.9.3-py311h80987f9_0 \n",
      "  aiosignal          conda-forge/noarch::aiosignal-1.3.1-pyhd8ed1ab_0 \n",
      "  annotated-types    conda-forge/noarch::annotated-types-0.6.0-pyhd8ed1ab_0 \n",
      "  async-timeout      conda-forge/noarch::async-timeout-4.0.3-pyhd8ed1ab_0 \n",
      "  bottleneck         pkgs/main/osx-arm64::bottleneck-1.3.7-py311hb9f6ed7_0 \n",
      "  brotli             conda-forge/osx-arm64::brotli-1.1.0-hb547adb_1 \n",
      "  brotli-bin         conda-forge/osx-arm64::brotli-bin-1.1.0-hb547adb_1 \n",
      "  colorama           conda-forge/noarch::colorama-0.4.6-pyhd8ed1ab_0 \n",
      "  contourpy          pkgs/main/osx-arm64::contourpy-1.2.0-py311h48ca7d4_0 \n",
      "  cycler             conda-forge/noarch::cycler-0.12.1-pyhd8ed1ab_0 \n",
      "  dataclasses-json   conda-forge/noarch::dataclasses-json-0.6.4-pyhd8ed1ab_0 \n",
      "  fonttools          pkgs/main/noarch::fonttools-4.25.0-pyhd3eb1b0_0 \n",
      "  frozenlist         pkgs/main/osx-arm64::frozenlist-1.4.0-py311h80987f9_0 \n",
      "  greenlet           pkgs/main/osx-arm64::greenlet-3.0.1-py311h313beb8_0 \n",
      "  importlib-metadata conda-forge/noarch::importlib-metadata-7.1.0-pyha770c72_0 \n",
      "  importlib_metadata conda-forge/noarch::importlib_metadata-7.1.0-hd8ed1ab_0 \n",
      "  importlib_resourc~ conda-forge/noarch::importlib_resources-6.4.0-pyhd8ed1ab_0 \n",
      "  joblib             conda-forge/noarch::joblib-1.4.0-pyhd8ed1ab_0 \n",
      "  jsonpatch          conda-forge/noarch::jsonpatch-1.33-pyhd8ed1ab_0 \n",
      "  jsonpointer        conda-forge/noarch::jsonpointer-2.0-py_0 \n",
      "  kiwisolver         pkgs/main/osx-arm64::kiwisolver-1.4.4-py311h313beb8_0 \n",
      "  langchain          conda-forge/noarch::langchain-0.1.15-pyhd8ed1ab_0 \n",
      "  langchain-communi~ conda-forge/noarch::langchain-community-0.0.32-pyhd8ed1ab_0 \n",
      "  langchain-core     conda-forge/noarch::langchain-core-0.1.42-pyhd8ed1ab_0 \n",
      "  langchain-text-sp~ conda-forge/noarch::langchain-text-splitters-0.0.1-pyhd8ed1ab_0 \n",
      "  langsmith          conda-forge/noarch::langsmith-0.1.45-pyhd8ed1ab_0 \n",
      "  libbrotlicommon    conda-forge/osx-arm64::libbrotlicommon-1.1.0-hb547adb_1 \n",
      "  libbrotlidec       conda-forge/osx-arm64::libbrotlidec-1.1.0-hb547adb_1 \n",
      "  libbrotlienc       conda-forge/osx-arm64::libbrotlienc-1.1.0-hb547adb_1 \n",
      "  marshmallow        conda-forge/noarch::marshmallow-3.21.1-pyhd8ed1ab_0 \n",
      "  matplotlib         pkgs/main/osx-arm64::matplotlib-3.8.0-py311hca03da5_0 \n",
      "  matplotlib-base    pkgs/main/osx-arm64::matplotlib-base-3.8.0-py311h7aedaa7_0 \n",
      "  multidict          pkgs/main/osx-arm64::multidict-6.0.4-py311h80987f9_0 \n",
      "  munkres            conda-forge/noarch::munkres-1.1.4-pyh9f0ad1d_0 \n",
      "  mypy_extensions    conda-forge/noarch::mypy_extensions-1.0.0-pyha770c72_0 \n",
      "  numexpr            pkgs/main/osx-arm64::numexpr-2.8.7-py311h6dc990b_0 \n",
      "  orjson             pkgs/main/osx-arm64::orjson-3.9.15-py311hc9796cf_0 \n",
      "  pandas             pkgs/main/osx-arm64::pandas-2.2.1-py311h7aedaa7_0 \n",
      "  prettytable        conda-forge/noarch::prettytable-3.10.0-pyhd8ed1ab_0 \n",
      "  py-cpuinfo         conda-forge/noarch::py-cpuinfo-9.0.0-pyhd8ed1ab_0 \n",
      "  pydantic           conda-forge/noarch::pydantic-2.5.3-pyhd8ed1ab_0 \n",
      "  pydantic-core      pkgs/main/osx-arm64::pydantic-core-2.14.6-py311hf0e4da2_0 \n",
      "  pyparsing          conda-forge/noarch::pyparsing-3.0.9-pyhd8ed1ab_0 \n",
      "  python-tzdata      conda-forge/noarch::python-tzdata-2024.1-pyhd8ed1ab_0 \n",
      "  scikit-learn       pkgs/main/osx-arm64::scikit-learn-1.2.2-py311h313beb8_1 \n",
      "  scipy              pkgs/main/osx-arm64::scipy-1.12.0-py311hc76d9b0_0 \n",
      "  sqlalchemy         pkgs/main/osx-arm64::sqlalchemy-2.0.25-py311h80987f9_0 \n",
      "  tenacity           conda-forge/noarch::tenacity-8.2.3-pyhd8ed1ab_0 \n",
      "  threadpoolctl      conda-forge/noarch::threadpoolctl-3.4.0-pyhc1e730c_0 \n",
      "  tomli              conda-forge/noarch::tomli-2.0.1-pyhd8ed1ab_0 \n",
      "  tqdm               conda-forge/noarch::tqdm-4.66.2-pyhd8ed1ab_0 \n",
      "  typing_inspect     conda-forge/noarch::typing_inspect-0.9.0-pyhd8ed1ab_0 \n",
      "  yarl               pkgs/main/osx-arm64::yarl-1.9.3-py311h80987f9_0 \n",
      "  zipp               conda-forge/noarch::zipp-3.17.0-pyhd8ed1ab_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  openssl              pkgs/main::openssl-3.0.13-h1a28f6b_0 --> conda-forge::openssl-3.2.1-h0d3ecfb_1 \n",
      "  pip                pkgs/main/osx-arm64::pip-23.3.1-py311~ --> conda-forge/noarch::pip-24.0-pyhd8ed1ab_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2024.3.11-~ --> conda-forge::ca-certificates-2024.2.2-hf0a4a13_0 \n",
      "  certifi            pkgs/main/osx-arm64::certifi-2024.2.2~ --> conda-forge/noarch::certifi-2024.2.2-pyhd8ed1ab_0 \n",
      "  jupyterlab         pkgs/main/osx-arm64::jupyterlab-4.0.1~ --> conda-forge/noarch::jupyterlab-4.0.9-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "\n",
      "CondaSystemExit: \n",
      "Operation aborted.  Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge pip pandas numpy matplotlib scikit-learn jupyterlab langchain prettytable py-cpuinfo tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f87a85-1796-4c94-b6e4-6825649475e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms # use v2 transforms for faster augmentations\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from helper_functions import get_nvidia_gpu_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a93eba-1d6e-49bf-b8a4-1cb31ae0ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    CPU_PROCESSOR = None\n",
    "\n",
    "    ### Get CPU Processor name ###\n",
    "    if not CPU_PROCESSOR:\n",
    "        try:\n",
    "            import cpuinfo\n",
    "            CPU_PROCESSOR = cpuinfo.get_cpu_info().get(\"brand_raw\").replace(\" \", \"_\")\n",
    "            print(f\"[INFO] CPU Processor: {CPU_PROCESSOR}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}, may have failed to get CPU_PROCESSOR name from cpuinfo, please install cpuinfo or set CPU_PROCESSOR manually\") \n",
    "\n",
    "    ### Setup device ###\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(f\"[INFO] MPS device found, using device: {device}\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"[INFO] CUDA device found, using device: {device}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print (f\"[INFO] MPS or CUDA device not found, using device: {device} (results will be much slower than using MPS or CUDA)\")\n",
    "\n",
    "    # Prevent torch from erroring with too many files open (happens on M3)\n",
    "    # See: https://github.com/pytorch/pytorch/issues/11201, https://github.com/CVMI-Lab/PLA/issues/20 \n",
    "    torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "    # Set random seed\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Create argument parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--batch_sizes\", default=\"16, 32, 64, 128, 256, 512, 1024\", help=\"Delimited list input of batch sizes to test, defaults to '16, 32, 64, 128, 256, 512, 1024'\", type=str)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=5, help=\"Number of epochs to train for, default is 5\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Convert batch_sizes to list\n",
    "    batch_size_args = [int(item.strip()) for item in args.batch_sizes.split(\",\")]\n",
    "\n",
    "    ### Set constants ###\n",
    "    GPU_NAME = get_nvidia_gpu_name()\n",
    "    BACKEND = \"pytorch\"\n",
    "    MODEL_NAME = \"resnet50\"\n",
    "    IMAGE_SIZE = 32\n",
    "    INPUT_SHAPE = (3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    NUM_WORKERS = os.cpu_count()\n",
    "    EPOCHS = args.epochs\n",
    "    BATCH_SIZES = batch_size_args\n",
    "    DATASET_NAME = \"CIFAR100\"\n",
    "\n",
    "    print(f\"[INFO] Testing model: {MODEL_NAME} on {DATASET_NAME} dataset with input shape {INPUT_SHAPE} for {EPOCHS} epochs across batch sizes: {BATCH_SIZES}\")\n",
    "\n",
    "\n",
    "    ### Prepare Data ### \n",
    "    simple_transform = transforms.Compose([\n",
    "        transforms.Resize(size=IMAGE_SIZE),\n",
    "        transforms.ToImage(), \n",
    "        transforms.ToDtype(torch.float32, scale=True)\n",
    "    ])\n",
    "\n",
    "    # Get Datasets\n",
    "    train_data = datasets.CIFAR10(root=\"data\",\n",
    "                                train=True,\n",
    "                                transform=simple_transform,\n",
    "                                download=True)\n",
    "\n",
    "    test_data = datasets.CIFAR10(root=\"data\",\n",
    "                                train=False,\n",
    "                                transform=simple_transform,\n",
    "                                download=True)\n",
    "\n",
    "    print(f\"[INFO] Number of training samples: {len(train_data)}, number of testing samples: {len(test_data)}\")\n",
    "\n",
    "    # Create DataLoaders\n",
    "    def create_dataloaders(batch_size, num_workers=NUM_WORKERS):\n",
    "        train_dataloader = DataLoader(train_data,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=num_workers,\n",
    "                                      pin_memory=False) # note: if you pin memory, you may get \"too many workers\" errors when recreating DataLoaders, see: https://github.com/Lightning-AI/pytorch-lightning/issues/18487#issuecomment-1740244601\n",
    "\n",
    "        test_dataloader = DataLoader(test_data,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=num_workers,\n",
    "                                     pin_memory=False)\n",
    "\n",
    "        return train_dataloader, test_dataloader\n",
    "\n",
    "    ### Train Step ###\n",
    "    def train_step(model: torch.nn.Module, \n",
    "                   dataloader: torch.utils.data.DataLoader, \n",
    "                   loss_fn: torch.nn.Module, \n",
    "                   optimizer: torch.optim.Optimizer,\n",
    "                   device: torch.device):\n",
    "        # Put model in train mode\n",
    "        model.train()\n",
    "        \n",
    "        # Setup train loss and train accuracy values\n",
    "        train_loss, train_acc = 0, 0\n",
    "        \n",
    "        # Loop through data loader data batches\n",
    "        for batch, (X, y) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            # Send data to target device\n",
    "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "    #         X, y = X.to(device, non_blocking=True, memory_format=torch.channels_last), y.to(device, non_blocking=True)\n",
    "    #         X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # 2. Calculate  and accumulate loss\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            train_loss += loss.item() \n",
    "\n",
    "            # 3. Optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 4. Loss backward\n",
    "            loss.backward()\n",
    "\n",
    "            # 5. Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate and accumulate accuracy metric across all batches\n",
    "            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "            train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "            \n",
    "        # Adjust metrics to get average loss and accuracy per batch \n",
    "        train_loss = train_loss / len(dataloader)\n",
    "        train_acc = train_acc / len(dataloader)\n",
    "        return train_loss, train_acc\n",
    "\n",
    "    ### Test Step ###\n",
    "    def test_step(model: torch.nn.Module, \n",
    "                dataloader: torch.utils.data.DataLoader, \n",
    "                loss_fn: torch.nn.Module,\n",
    "                device: torch.device):\n",
    "        # Put model in eval mode\n",
    "        model.eval() \n",
    "        \n",
    "        # Setup test loss and test accuracy values\n",
    "        test_loss, test_acc = 0, 0\n",
    "        \n",
    "        # Turn on inference context manager\n",
    "        with torch.inference_mode():\n",
    "            # Loop through DataLoader batches\n",
    "            for batch, (X, y) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "                # Send data to target device\n",
    "                X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "    #             X, y = X.to(device, non_blocking=True, memory_format=torch.channels_last), y.to(device, non_blocking=True)\n",
    "    #             X, y = X.to(device), y.to(device)\n",
    "        \n",
    "                # 1. Forward pass\n",
    "                test_pred_logits = model(X)\n",
    "\n",
    "                # 2. Calculate and accumulate loss\n",
    "                loss = loss_fn(test_pred_logits, y)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                # Calculate and accumulate accuracy\n",
    "                test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "                test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "                \n",
    "        # Adjust metrics to get average loss and accuracy per batch \n",
    "        test_loss = test_loss / len(dataloader)\n",
    "        test_acc = test_acc / len(dataloader)\n",
    "        return test_loss, test_acc\n",
    "\n",
    "    # 1. Take in various parameters required for training and test steps\n",
    "    def train_and_test_model(model: torch.nn.Module, \n",
    "                            train_dataloader: torch.utils.data.DataLoader, \n",
    "                            test_dataloader: torch.utils.data.DataLoader, \n",
    "                            optimizer: torch.optim.Optimizer,\n",
    "                            loss_fn: torch.nn.Module,\n",
    "                            epochs: int,\n",
    "                            device: torch.device,\n",
    "                            eval: bool=False):\n",
    "        \n",
    "        print(f\"[INFO] Training model {model.__class__.__name__} on device '{device}' for {epochs} epochs...\")\n",
    "        \n",
    "        results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
    "\n",
    "        # Loop through training and testing steps for a number of epochs\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            # Do eval before training (to see if there's any errors)\n",
    "            if eval:\n",
    "                test_loss, test_acc = test_step(model=model,\n",
    "                                            dataloader=test_dataloader,\n",
    "                                            loss_fn=loss_fn,\n",
    "                                            device=device)\n",
    "            \n",
    "            train_loss, train_acc = train_step(model=model,\n",
    "                                            dataloader=train_dataloader,\n",
    "                                            loss_fn=loss_fn,\n",
    "                                            optimizer=optimizer,\n",
    "                                            device=device)\n",
    "            \n",
    "            \n",
    "            # Print out what's happening\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} | \"\n",
    "                f\"train_loss: {train_loss:.4f} | \"\n",
    "                f\"train_acc: {train_acc:.4f} | \"\n",
    "            )\n",
    "\n",
    "            if eval:\n",
    "                print(\n",
    "                    f\"Epoch: {epoch+1} | \"\n",
    "                    f\"test_loss: {test_loss:.4f} | \"\n",
    "                    f\"test_acc: {test_acc:.4f} | \"\n",
    "                )\n",
    "\n",
    "            # Save results to dictionary\n",
    "            results[\"train_loss\"].append(train_loss)\n",
    "            results[\"train_acc\"].append(train_acc)\n",
    "            if eval:\n",
    "                results[\"test_loss\"].append(test_loss)\n",
    "                results[\"test_acc\"].append(test_acc)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_results(batch_size_training_results, target_dir=\"results_pytorch_cv\"):\n",
    "        # Create CSV filename\n",
    "        if GPU_NAME:\n",
    "            csv_filename = f\"{GPU_NAME.replace(' ', '_')}_{DATASET_NAME}_{MODEL_NAME}_{INPUT_SHAPE[-1]}_{BACKEND}_results.csv\"\n",
    "        else:\n",
    "            csv_filename = f\"{CPU_PROCESSOR}_{DATASET_NAME}_{MODEL_NAME}_{INPUT_SHAPE[-1]}_{BACKEND}_results.csv\"\n",
    "\n",
    "        # Make the target results directory if it doesn't exist (include the parents)\n",
    "        target_results_dir = target_dir\n",
    "        results_path = Path(\"results\") / target_results_dir\n",
    "        results_path.mkdir(parents=True, exist_ok=True)\n",
    "        csv_filepath = results_path / csv_filename\n",
    "\n",
    "        # Turn dict into DataFrame \n",
    "        df = pd.DataFrame(batch_size_training_results) \n",
    "\n",
    "        # Save to CSV\n",
    "        print(f\"[INFO] Saving results to: {csv_filepath}\")\n",
    "        df.to_csv(csv_filepath, index=False)\n",
    "\n",
    "    def train_and_time(batch_sizes=BATCH_SIZES,\n",
    "                       epochs=EPOCHS,\n",
    "                       device=device):\n",
    "\n",
    "        batch_size_training_results = []\n",
    "\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"[INFO] Training with batch size {batch_size} for {epochs} epochs...\")\n",
    "            # Create an instance of resnet50\n",
    "            model = torchvision.models.resnet50(num_classes=100).to(device)\n",
    "            # model = torch.compile(model) # potential way to speed up model\n",
    "\n",
    "            # Setup loss function and optimizer\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "\n",
    "            # Create DataLoaders\n",
    "            train_dataloader, test_dataloader = create_dataloaders(batch_size=batch_size)\n",
    "\n",
    "            try:\n",
    "                # Start the timer\n",
    "                start_time = timer()\n",
    "\n",
    "                # Train model\n",
    "                model_results = train_and_test_model(model=model, \n",
    "                                                    train_dataloader=train_dataloader,\n",
    "                                                    test_dataloader=test_dataloader,\n",
    "                                                    optimizer=optimizer,\n",
    "                                                    loss_fn=loss_fn, \n",
    "                                                    epochs=epochs,\n",
    "                                                    device=device,\n",
    "                                                    eval=False) # don't eval, just test training time\n",
    "\n",
    "                # End the timer\n",
    "                end_time = timer()\n",
    "\n",
    "                total_training_time = end_time - start_time\n",
    "                avg_time_per_epoch = total_training_time / epochs\n",
    "\n",
    "                batch_size_training_results.append({\"batch_size\": batch_size,\n",
    "                                                    \"avg_time_per_epoch\": avg_time_per_epoch})\n",
    "                save_results(batch_size_training_results)\n",
    "                print(f\"[INFO] Finished training with batch size {batch_size} for {epochs} epochs, total time: {round(total_training_time, 3)} seconds, avg time per epoch: {round(avg_time_per_epoch, 3)} seconds\\n\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[INFO] Error: {e}\")\n",
    "                print(f\"[INFO] Failed training with batch size {batch_size} for {epochs} epochs...\\n\\n\")\n",
    "                batch_size_training_results.append({\"batch_size\": batch_size,\n",
    "                                                    \"avg_time_per_epoch\": \"FAILED\"})\n",
    "                save_results(batch_size_training_results)\n",
    "                break\n",
    "                \n",
    "        return batch_size_training_results\n",
    "\n",
    "    ### Train an time model ### \n",
    "    batch_size_training_results = train_and_time(batch_sizes=BATCH_SIZES,\n",
    "                                                 epochs=EPOCHS,\n",
    "                                                 device=device)\n",
    "\n",
    "    print(\"[INFO] Finished training with all batch sizes.\")        \n",
    "\n",
    "    print(f\"[INFO] Results:\\n{batch_size_training_results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
